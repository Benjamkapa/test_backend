<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Simgel AI</title>
  <style>
    /* Same styles from before â€” untouched */
    * { box-sizing: border-box; margin: 0; padding: 0; font-family: comic sans ms; }

    body {
      background: radial-gradient(circle at center, #1a1a1a, #0a0a0a);
      color: #fff;
      font-family: 'Segoe UI', sans-serif;
      height: 100vh;
      display: flex;
      flex-direction: column;
      overflow: hidden;
    }

    #mainContainer {
      flex: 1;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      padding: 20px;
    }

    #orbContainer {
      position: relative;
      width: 60vw;
      max-width: 300px;
      aspect-ratio: 1;
      border-radius: 50%;
      background: radial-gradient(circle, #ff85c1, #4b0082);
      box-shadow: 0 0 50px rgba(255, 105, 180, 0.5);
      display: flex;
      align-items: center;
      justify-content: center;
      animation: rippleIdle 4s infinite ease-in-out;
      cursor: pointer;
    }

    #orbContainer.speaking {
      animation: rippleSpeaking 2s infinite ease-in-out;
    }

    @keyframes rippleIdle {
      0%, 100% { transform: scale(1); box-shadow: 0 0 50px rgba(255, 105, 180, 0.2); }
      50% { transform: scale(1.1); box-shadow: 0 0 80px rgba(255, 105, 180, 0.7); }
    }

    @keyframes rippleSpeaking {
      0%, 100% { transform: scale(1); box-shadow: 0 0 40px rgba(255, 105, 180, 0.6); }
      50% { transform: scale(1.2); box-shadow: 0 0 90px rgba(255, 182, 193, 1); }
    }

    #responseText {
      font-size: 0.9rem;
      text-align: center;
      padding: 1rem;
      max-width: 80%;
      color: white;
      opacity: 0;
      transition: opacity 0.3s;
    }

    #inputContainer {
        position: fixed;
        bottom: 4rem;
        left: 0;
        right: 0;
        padding-inline: 2em;
        padding-block: 1em;
        backdrop-filter: blur(10px);
        z-index: 10;
    }

    @media screen and (min-width: 600px) {
        #inputContainer {
            width: 50em;
            left: 50%;
            right: auto;
            transform: translateX(-50%);
        }
    }

    #chatInput {
      width: 100%;
      padding: 15px;
      border: none;
      border-radius: 25px;
      background: rgba(255, 255, 255, 0.1);
      color: white;
      font-size: 16px;
      outline: none;
      transition: all 0.3s ease;
    }

    #chatInput:focus {
      background: rgba(255, 255, 255, 0.15);
      box-shadow: 0 0 15px rgba(255, 133, 193, 0.3);
    }

    #historyBtn {
      position: absolute;
      top: 20px;
      left: 20px;
      background: #4b0082;
      color: white;
      border: none;
      padding: 0.6rem 1rem;
      border-radius: 50%;
      cursor: pointer;
      font-size: 14px;
    }

    #historyModal {
      position: fixed;
      top: 0; left: 0;
      width: 100%; height: 100%;
      display: none;
      align-items: center;
      justify-content: center;
      background-color: rgba(0, 0, 0, 0.7);
      z-index: 10;
    }

        #micStatus {
        position: fixed;
        bottom: 80px;
        left: 50%;
        transform: translateX(-50%);
        background: rgba(255, 133, 193, 0.2);
        padding: 10px 20px;
        border-radius: 20px;
        backdrop-filter: blur(5px);
        opacity: 0;
        transition: opacity 0.3s;
        z-index: 100;
    }

    #micStatus.active {
        opacity: 1;
    }

    #historyContent {
      background: #1e1e1e;
      width: 90%;
      max-width: 500px;
      max-height: 80vh;
      overflow-y: auto;
      padding: 20px;
      border-radius: 15px;
      color: white;
    }

    #historyContent h2 {
      margin-bottom: 1rem;
    }

    .history-entry {
      margin-bottom: 1rem;
      padding: 10px;
      background: rgba(255, 255, 255, 0.05);
      border-radius: 10px;
    }

    .history-entry p {
      margin: 5px 0;
    }

    #closeModal, #clearHistory {
      background: #ff85c1;
      color: black;
      padding: 0.5rem 1rem;
      margin-top: 1rem;
      margin-right: 1rem;
      border: none;
      border-radius: 10px;
      cursor: pointer;
    }
  </style>
</head>
<body>
  <div id="mainContainer">
    <div id="orbContainer">
      <div id="responseText"></div>
    </div>
  </div>

  <div id="inputContainer">
    <input id="chatInput" type="text" placeholder="Type to Simgel..." autocomplete="off" />
  </div>

  <button id="historyBtn">ðŸ“œ</button>

  <div id="historyModal">
    <div id="historyContent">
      <h2>ðŸ’¬ Chat History</h2>
      <div id="historyList"></div>
      <button id="clearHistory">Clear</button>
      <button id="closeModal">Close</button>
    </div>
  </div>

  <!-- Add this after the historyModal div -->
  <div id="micStatus">ðŸŽ¤ Listening...</div>

  <script>
    const orb = document.getElementById("orbContainer");
    const responseText = document.getElementById("responseText");
    const chatInput = document.getElementById("chatInput");
    const historyModal = document.getElementById("historyModal");
    const historyList = document.getElementById("historyList");
    const closeModal = document.getElementById("closeModal");
    const clearHistory = document.getElementById("clearHistory");

    let chatHistory = [];

    // Try native or fallback to webkit
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    const recognition = SpeechRecognition ? new SpeechRecognition() : null;
    if (recognition) {
      recognition.continuous = false;
      recognition.interimResults = false;
      recognition.lang = 'en-US';
    }

    function removeEmojis(text) {
      return text.replace(/[\u{1F600}-\u{1F64F}\u{1F300}-\u{1F5FF}\u{1F680}-\u{1F6FF}\u{1F1E0}-\u{1F1FF}\u{2702}-\u{27B0}\u{24C2}-\u{1F251}\u{1F900}-\u{1F9FF}\u{1F910}-\u{1F93F}]/gu, '');
    }

    // Replace the existing handleInput function with this version
    async function handleInput(input) {
        if (!input.trim()) return;
        
        // Log the input being sent
        console.log('ðŸŽ¯ Sending to backend:', input);
        chatInput.value = "";

        try {
            console.log('ðŸ“¡ Making request to backend...');
            const res = await fetch("http://127.0.0.1:5000/api/generate", {
                method: "POST",
                headers: { "Content-Type": "application/json" },
                body: JSON.stringify({ input })
            });

            const data = await res.json();
            console.log('ðŸ“¥ Received from backend:', data);
            
            const msg = data.response || "I'm here";
            speakSimgel(msg, input);
        } catch (error) {
            console.error('âŒ Backend Error:', error);
            speakSimgel("Sorry, I'm having trouble connecting right now ðŸ¥º", input);
        }
    }

    function speakSimgel(text, input = "") {
      const synth = window.speechSynthesis;
      const cleanText = removeEmojis(text);
      const utterance = new SpeechSynthesisUtterance(cleanText);

      const voices = synth.getVoices();
      const preferredVoice = voices.find(v => v.name.includes("Zira")) || voices[0];
      utterance.voice = preferredVoice;

      utterance.onstart = () => {
        orb.classList.add("speaking");
        responseText.innerText = text;
        responseText.style.opacity = 1;
      };

      utterance.onend = () => {
        orb.classList.remove("speaking");
        responseText.style.opacity = 0;
      };

      synth.speak(utterance);

      if (input) {
        chatHistory.push({ user: input, simgel: text });
      }
    }

    // Replace the startVoiceInput function with this enhanced version
    function startVoiceInput() {
        if (!recognition) {
            alert("Speech recognition is not supported in this browser.");
            return;
        }

        const micStatus = document.getElementById("micStatus");
        let silenceTimer = null;
        let lastSpeechTime = Date.now();
        let finalTranscript = '';
        let isListening = false;

        recognition.continuous = true;
        recognition.interimResults = true;

        recognition.start();
        micStatus.classList.add("active");
        isListening = true;

        recognition.onstart = () => {
            console.log("ðŸŽ¤ Started listening...");
            orb.classList.add("speaking");
            lastSpeechTime = Date.now();
            finalTranscript = '';
        };

        recognition.onresult = (event) => {
            lastSpeechTime = Date.now();
            
            let interimTranscript = '';
            
            // Accumulate all results
            for (let i = event.resultIndex; i < event.results.length; i++) {
                const transcript = event.results[i][0].transcript;
                
                if (event.results[i].isFinal) {
                    finalTranscript = transcript;
                    console.log('ðŸŽ¤ Final part:', finalTranscript);
                } else {
                    interimTranscript = transcript;
                    console.log('ðŸŽ¤ Hearing:', interimTranscript);
                }
            }

            // Show interim results in input field
            chatInput.value = interimTranscript || finalTranscript;

            // Reset silence detection
            clearTimeout(silenceTimer);
            silenceTimer = setTimeout(() => {
                // Only stop if we have actual content and 3 seconds of silence
                if (Date.now() - lastSpeechTime > 3000 && (finalTranscript || interimTranscript)) {
                    console.log('ðŸŽ¤ Silence detected, stopping...');
                    recognition.stop();
                    if (finalTranscript || interimTranscript) {
                        handleInput(finalTranscript || interimTranscript);
                    }
                }
            }, 3000); // Wait 3 seconds of silence before stopping
        };

        recognition.onerror = (event) => {
            console.error("âŒ Speech recognition error:", event.error);
            orb.classList.remove("speaking");
            micStatus.classList.remove("active");
            isListening = false;
        };

        recognition.onend = () => {
            console.log("ðŸŽ¤ Recognition ended");
            orb.classList.remove("speaking");
            micStatus.classList.remove("active");
            clearTimeout(silenceTimer);
            isListening = false;

            // If recognition ends with content but no final result, send what we have
            if (!finalTranscript && chatInput.value) {
                handleInput(chatInput.value);
            }
        };

        // Add longer maximum duration (45 seconds)
        setTimeout(() => {
            if (isListening) {
                console.log("ðŸŽ¤ Maximum duration reached");
                recognition.stop();
            }
        }, 45000);

        // Update micStatus text based on state
        micStatus.innerHTML = 'ðŸŽ¤ Listening... (tap anywhere to stop)';
    }

    // Update the click-away handler
    document.addEventListener('click', (event) => {
        if (!orb.contains(event.target) && recognition) {
            console.log('ðŸŽ¤ Clicked away, stopping recognition');
            recognition.stop();
        }
    });

    // Add real-time input monitoring
    chatInput.addEventListener("input", (e) => {
        console.log('âŒ¨ï¸ Current input:', e.target.value);
    });

    chatInput.addEventListener("keypress", (e) => {
      if (e.key === "Enter") {
        e.preventDefault();
        handleInput(chatInput.value);
      }
    });

    orb.addEventListener("click", () => {
      startVoiceInput();
    });

    window.speechSynthesis.onvoiceschanged = () => {
      window.speechSynthesis.getVoices();
    };

    window.addEventListener("load", () => {
      speakSimgel("Hi! I'm Simgel. Tap me or type to chat!");
    });

    document.getElementById("historyBtn").addEventListener("click", () => {
      updateHistoryModal();
      historyModal.style.display = "flex";
    });

    closeModal.addEventListener("click", () => {
      historyModal.style.display = "none";
    });

    clearHistory.addEventListener("click", () => {
      chatHistory = [];
      updateHistoryModal();
    });

    function updateHistoryModal() {
      historyList.innerHTML = "";
      chatHistory.forEach((entry) => {
        const div = document.createElement("div");
        div.classList.add("history-entry");
        div.innerHTML = `
          <p><strong>You:</strong> ${entry.user}</p>
          <p><strong>Simgel:</strong> ${entry.simgel}</p>
        `;
        historyList.appendChild(div);
      });
    }
  </script>
</body>
</html>
